{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d576ad26-2254-4014-b65f-9a33cc3a5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import perf_counter\n",
    "\n",
    "notebook_dir = Path().resolve()\n",
    "sys.path.append(str(notebook_dir.parent / \"src\"))\n",
    "\n",
    "from preprocessor.preprocessing import IMDBPreprocessor\n",
    "from models.naive_bayes import NaiveBayes\n",
    "from models.knn import KNN\n",
    "from vectorizer.bag_of_words import BoWVectorizer  \n",
    "from vectorizer.tfidf import TfidfVectorizerScratch\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "project_root = notebook_dir.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad59b778-9b6a-4440-8aae-02e378e7fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(project_root / \"data\" / \"imdb_reviews.parquet\")\n",
    "df = df[[\"review\", \"sentiment\"]].dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2cf68d4-9411-4376-9bbf-b4782b6790cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    df[\"review\"].astype(str), df[\"sentiment\"].astype(int), test_size=0.2, random_state=42, stratify=df[\"sentiment\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d127c0e7-49d1-4872-b635-a8b7937254db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tok = X_train_text.str.split().tolist()\n",
    "X_test_tok  = X_test_text.str.split().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94ff3ad-1bf8-41ce-8de1-909429b064b5",
   "metadata": {},
   "source": [
    "## BOW + naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b665de31-c646-4cc0-b7cb-af870d8b7556",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = {\n",
    "    \"bow\": lambda: BoWVectorizer(binary=False, min_df=2),\n",
    "    \"bow_binary\": lambda: BoWVectorizer(binary=True, min_df=2),\n",
    "    \"tfidf\": lambda: TfidfVectorizerScratch(min_df=2, sublinear_tf=False, l2_norm=False),\n",
    "    \"tfidf_norm\": lambda: TfidfVectorizerScratch(min_df=2, sublinear_tf=True, l2_norm=True),\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"naive_bayes\": lambda: NaiveBayes(alpha=1.0),\n",
    "    \"knn\": lambda: KNN(k=7, distance_metric=\"cosine\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98ef3545-e134-4ff1-b5a3-23bc103b1956",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.70 GiB for an array with shape (19758, 63814) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m model \u001b[38;5;241m=\u001b[39m m_ctor()\n\u001b[0;32m     13\u001b[0m t1 \u001b[38;5;241m=\u001b[39m perf_counter()\n\u001b[1;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m perf_counter() \u001b[38;5;241m-\u001b[39m t1\n\u001b[0;32m     17\u001b[0m t2 \u001b[38;5;241m=\u001b[39m perf_counter()\n",
      "File \u001b[1;32mJ:\\IMDB_Macromill\\src\\models\\naive_bayes.py:30\u001b[0m, in \u001b[0;36mNaiveBayes.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     28\u001b[0m feat_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((n_classes, n_features), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ci \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_classes):\n\u001b[1;32m---> 30\u001b[0m     feat_counts[ci] \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mci\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Likelihoods with Laplace smoothing\u001b[39;00m\n\u001b[0;32m     33\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 4.70 GiB for an array with shape (19758, 63814) and data type float32"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "artifacts = {}  # (vec_name, model_name) -> dict(vectorizer, model, y_pred, X_tr, X_te)\n",
    "\n",
    "for v_name, v_ctor in vectorizers.items():\n",
    "    vec = v_ctor()\n",
    "    t0 = perf_counter()\n",
    "    X_tr = vec.fit_transform(X_train_tok)\n",
    "    X_te = vec.transform(X_test_tok)\n",
    "    vec_time = perf_counter() - t0\n",
    "\n",
    "    for m_name, m_ctor in models.items():\n",
    "        model = m_ctor()\n",
    "        t1 = perf_counter()\n",
    "        model.fit(X_tr, y_train.tolist())\n",
    "        fit_time = perf_counter() - t1\n",
    "\n",
    "        t2 = perf_counter()\n",
    "        y_pred = model.predict(X_te)\n",
    "        pred_time = perf_counter() - t2\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1  = f1_score(y_test, y_pred)\n",
    "\n",
    "        results.append({\n",
    "            \"vectorizer\": v_name,\n",
    "            \"model\": m_name,\n",
    "            \"accuracy\": acc,\n",
    "            \"f1\": f1,\n",
    "            \"vec_time_s\": round(vec_time, 3),\n",
    "            \"fit_time_s\": round(fit_time, 3),\n",
    "            \"pred_time_s\": round(pred_time, 3),\n",
    "        })\n",
    "\n",
    "        artifacts[(v_name, m_name)] = {\n",
    "            \"vectorizer\": vec,\n",
    "            \"model\": model,\n",
    "            \"y_pred\": y_pred,\n",
    "            \"X_tr\": X_tr,\n",
    "            \"X_te\": X_te,\n",
    "        }\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values([\"accuracy\", \"f1\"], ascending=False).reset_index(drop=True)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965269e-4642-4318-a558-4db04c9e3b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text",
   "language": "python",
   "name": "text"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
